# Технологии хранения больших данных

Выполнили: Быковченко Софья Алексеевна, Мальцева Юлия Игоревна

Источник данных : Aviasales
# Лабораторная работа №1 “Работа с Airflow. ETL-процесс.”: 
В рамках данной работы вам необходимо реализовать ETL процесс, отвечающий за сбор и загрузку сырых данных в хранилище (слой ODS). База данных должна быть выбрана командой, выбор необходимо аргументировать. Оркестрация ETL процессов должна быть реализована с помощью Apache Airflow (https://airflow.apache.org/). 
## Этапы выполнения:
- [x] Развернуть сервис Airflow в Docker-контейнере, используя docker-compose 
конфигурацию (примеры можно найти в официальной документации, 
https://airflow.apache.org/docs/apache-airflow/stable/howto/docker-compose/index.html); 
- [x] Выбрать 3 различных сервиса для хранения данных. Например: s3, mongodb, 
oracle. Добавить конфигурацию для развертывания хранилищ в docker-compose. 
- [x] Реализовать не менее 3 различных ETL процессов (DAGов). При нехватке 
данных на одной платформе, данные можно брать с нескольких. Например: ozon + wildberries, aviasales + tutu.ru; Данные можно разделять логически в рамках одного источника: комментарии, товары, отзывы. 
- [x] В результате работы ETL процессов данные должны быть выгружены в выбранные базы данных; 
- [x] Провести сравнительный анализ выбранных хранилищ данных. Сравнительные критерии необходимо выбрать самостоятельно. Выбрать наиболее подходящее хранилище для полученных данных. 

Для защиты необходимо предоставить отчет, описывающий этапы выполнения работы, а также исходный код ETL процессов и docker-compose файл. 

Обязательным условием является демонстрация работы: веб интерфейс Airflow, выгруженные данные в базах данных, сравнительный анализ в виде графиков и/или таблиц.

## Отчёт

В данной лабораторной работе необходимо было реализовать ETL-процесс (Extract, Transform, Load ) для загрузки сырых данных в слой ODS (Operational Data Store)
с использованием Apache Airflow.

Для демонстрации ETL-процесса в качестве источника данных используется **API Aviasales**, предоставляемое через платформу Travelpayouts.

### Подготовка окружения
Перед началом реализации ETL-процессов была выполнена подготовка окружения.

1. Создание рабочей директории
2. Получение docker-compose.yaml. Официальный файл конфигурации Apache Airflow для Docker Compose был загружен из документации:
`curl -L "https://airflow.apache.org/docs/apache-airflow/2.7.3/docker-compose.yaml" -o docker-compose.yml`
3. Создан файл .env. Файл .env хранит переменные окружения для Airflow, упрощая настройку и переносимость системы.
`_PIP_ADDITIONAL_REQUIREMENTS` — дополнительные Python-библиотеки.
`AIRFLOW_UID` — UID пользователя контейнера для корректных прав на файлы.
4. В файл docker-compose.yml были добавлены три выбранных нами сервиса для реализации слоя ODS: `mongodb-ods`, `redis-ods`, `oracle-ods`
Также были добавлены соответствующие volumes для сохранения данных между перезапусками контейнеров: `mongodb_data:`, `redis_data:`, `oracle_data:`.
Эти тома обеспечивают сохранность данных в MongoDB, Redis и Oracle между перезапусками контейнеров.
5. Выполнена инициализация метаданных Airflow и создание учётной записи администратора: `docker-compose up airflow-init`
6. После успешной инициализации запущены все сервисы: `docker-compose up -d`
7. Веб-интерфейс Airflow стал доступен по адресу http://localhost:8080 (логин/пароль airflow/airflow)
8. Через личный кабинет Travelpayouts был получен API-токен, необходимый для запросов к данным Aviasales:
![img.png](img_readme/img.png)
9.  Была успешно проверена работоспособность API на примитивных запросах.

### Реализация ETL-процессов
В рамках лабораторной работы было разработано три DAGа, каждый из которых реализует отдельный сценарий сбора и обработки данных из API Aviasales. 
Все DAGи следуют единой архитектуре Extract -> Transform -> Load, но работают с разными эндпоинтами API и решают разные задачи.

#### DAG 1. aviasales_cheap_tickets — сбор дешёвых билетов
Цель: получение актуальных предложений на самые дешёвые авиабилеты из Москвы (MOW) в популярные направления (Санкт-Петербург, Сочи, Новосибирск и др.) на октябрь 2025 года.

Источник:
`/aviasales/v3/grouped_prices` — возвращает сгруппированные по датам вылета предложения на билеты, найденные пользователями за последние 48 часов

***Этапы ETL:***
- extract - запрос к API для 8 направлений, извлечение данных о цене, авиакомпании, времени вылета, количестве пересадок
- transform - приведение типов, расчёт булевого флага `is_direct`, категоризация по цене (cheap/normal).
- load - одновременная загрузка в MongoDB, Redis и Oracle
  - MongoDB хранение полных JSON документов для гибкого анализа
  - Redis кэширование по ключу `ticket:{ticket_id}` для быстрого доступа
  - Oracle структурированное хранение в таблице `cheap_tickets` для SQL-запросов

DAG запускается каждые 6 часов, что позволяет отслеживать динамику цен

#### DAG 2. aviasales_popular_directions — анализ популярных направлений
Цель: получение данных о самых востребованных маршрутах из Москвы, основанных на статистике поисков пользователей Aviasales.

Источник:
`/v1/city-directions` — возвращает популярные направления с актуальными ценами и рейсами

***Этапы ETL:***
- extract - запрос для origin=MOW, получение списка направлений с ценами и рейсами
- transform - категоризация направлений по популярности (popular если цена < 15 000 руб), приведение типов
- load - загрузка в те же три хранилища, но в отдельные таблицы
  - MongoDB `popular_directions`
  - Redis ключи вида `direction:MOW:LED`
  - Oracle `popular_directions`

Эти данные помогают понять, какие направления наиболее востребованы, и могут использоваться для рекомендательных систем.

#### DAG 3. aviasales_price_trends — анализ цен по календарю
Цель: сбор динамики цен на билеты по дням в рамках одного месяца (октябрь 2025) для маршрута Москва - Санкт-Петербург.

Источник:
`/v1/prices/calendar` — возвращает цены на каждый день месяца

***Этапы ETL:***
- extract - запрос для маршрута MOW-LED, получение цены на каждый день октября
- transform - расчёт is_direct, категоризация по цене (cheap/normal), формирование уникального ticket_id
- load - загрузка в
  - MongoDB коллекция `price_trends`
  - Redis ключи `price_trend:{ticket_id}`
  - Oracle таблица `price_trends`

Позволяет строить графики изменения цен во времени и находить оптимальные даты для покупки билетов.

### MongoDB
![img_2.png](img_readme/img_2.png)
![img_3.png](img_readme/img_3.png)
![img_4.png](img_readme/img_4.png)

Подключение к MongoDB
`docker exec -it mongodb-ods mongosh -u root -p example --authenticationDatabase admin`

В MongoDB
- use aviasales_ods
- db.cheap_tickets.find().pretty()
- db.cheap_tickets.countDocuments()
- db.cheap_tickets.find({"price_category": "cheap"}).count()
- db.cheap_tickets.aggregate([{$group: {_id: "$destination", count: {$sum: 1}}}])

### Redis
![img_5.png](img_readme/img_5.png)
![img_6.png](img_readme/img_6.png)
![img_7.png](img_readme/img_7.png)

Подключение к Redis
`docker exec -it redis-ods redis-cli`

В Redis:
- KEYS ticket:*
- HGETALL ticket:SU_1448_SVX
- HLEN ticket:SU_1448_SVX
- DBSIZE

### Oracle
![img_8.png](img_readme/img_8.png)
![img_9.png](img_readme/img_9.png)

Подключение к Oracle
`docker exec -it oracle-ods sqlplus system/oracle@//localhost:1521/XEPDB1`

В Oracle:
- SELECT COUNT(*) FROM cheap_tickets;
- SET LINESIZE 200
SET PAGESIZE 50
COLUMN ticket_id FORMAT a15
COLUMN origin FORMAT a6
COLUMN destination FORMAT a11
COLUMN departure_at FORMAT a19
COLUMN airline FORMAT a7
COLUMN flight_number FORMAT a13
COLUMN price_category FORMAT a13
COLUMN extracted_at FORMAT a19
COLUMN route FORMAT a8
SELECT ticket_id, origin, destination, departure_at, price, airline, flight_number, transfers, duration, is_direct, price_category, extracted_at, route FROM cheap_tickets WHERE ROWNUM <= 10;
- SELECT destination, COUNT(*), AVG(price) FROM cheap_tickets GROUP BY destination; 
- SELECT price_category, COUNT(*) FROM cheap_tickets GROUP BY price_category;

### Сравнительный анализ выбранных хранилищ данных

Для сравнения выбранных хранилищ данных был разработан тестовый DAG. Наша цель была не просто измерить абстрактную производительность, 
а понять какая база данных лучше всего подходит для реальных задач нашей системы анализа авиаперелётов.

Были выбраны следующие критерии сравнения:
- **Производительность записи** отражает, насколько быстро система может сохранять новые данные. В нашем случае данные 
поступают из внешнего API Aviasales регулярно, большими порциями (ETL-процесс), поэтому скорость записи напрямую влияет 
на производительность всей системы.
- **Производительность чтения**. Хранилище активно используется для выборок (получение билетов, направлений и трендов).
Высокая скорость чтения нужна при обращении клиентских приложений и при формировании отчётов в Airflow.
- **Аналитические возможности**. После загрузки данных требуется их обработка и анализ (например фильтрация по цене или направлению).
Значит для нас важно оценить может ли база данных выполнять сложные запросы и агрегировать данные без дополнительной обработки на стороне приложения.

Мы создали тестовые данные — 500 записей об авиабилетах с разными ценами, авиакомпаниями и условиями перелётов. 
Для каждой базы данных выполнили одинаковые операции
- массовую вставку данных
- затем поиск по условию (билеты дешевле 8000 рублей)
- везде замеряли время выполнения

![img_1.png](img_readme/img_1.png)

![performance_chart.png](img_readme/performance_chart.png)

#### Вывод по результатам анализа
`MongoDB` показала лучшие результаты по скорости записи и чтения, а также обладает достаточными аналитическими возможностями.
Запись 500 билетов всего за 0.105 секунды (почти в 3 раза быстрее Oracle). 
При этом она не пожертвовала функциональностью ради скорости. Быстро находит 150 билетов по цене за 0.011 секунды, фильтрует по авиакомпаниям и другим параметрам. 

`Redis` оказался неэффективным для пакетной записи и не поддерживает сложные запросы, поэтому подходит лишь для кэширования.
Запись данных заняла 0.239 секунды, что медленнее MongoDB. Но главная проблема в ограниченной функциональности. 
Redis не умеет выполнять поиск по условиям типа "найти все билеты дешевле 8000 рублей". Он может только читать заранее известные записи по их ID (100 записей за 0.056 секунды). 
Это делает его не очень полезным для аналитики, но хорошим вариантом для кэширования часто запрашиваемых маршрутов.

`Oracle` имеет хорошие аналитические возможности, но проигрывает по скорости записи. 
Она так же успешно, как и MongoDB, справляется со сложными запросами и находит нужные данные (150 записей за 0.014 секунды). 
Однако запись данных в Oracle занимает 0.304 секунды. Почти в 3 раза больше времени, чем в MongoDB. Для системы, где цены на билеты обновляются постоянно, 
такая медлительность становится недостатком. Oracle подходит для глубокого анализа, но не для оперативной работы с постоянно меняющимися данными.

#### Итоговое решение
Для хранения и обработки данных, получаемых из API Aviasales, наиболее подходящим хранилищем является MongoDB. 
Оно сочетает в себе высокую производительность и простоту интеграции в ETL-процесс.
